<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Kray's Portfolio</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Cabin:700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/grayscale.css" rel="stylesheet">
	
	
  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">Home</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
      </div>
    </nav>

    <!-- About Section -->
    <section id="about" class="content-section text-center">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Geocoding with Python <i class="fa fa-terminal"></i></h2>
				<p class="portf-text">I was tasked with mapping out the donors to a nonprofit in West Michigan. The CSV of donors numbered over 10,000.
				Originally, I thought about using the <strong>geopy</strong> Python library for geocoding. It makes the process of geocoding through your preferred API quite simple.
				For example, you can use the Open Street Map API: <a href="https://wiki.openstreetmap.org/wiki/Nominatim">Nominatum</a>.</p>
				<p class="portf-text">However, after cross-checking some results, I found their accuracy to be inadequate. For now, since I want to map the results on <a href="https://carto.com">CARTO</a>,
				I have written off using Google's API because using their data would force me to use a Google basemap. Moreover, Google will only  geocode 2,500 addresses per day,
				which would slow down the processing of over 10,000 addresses. </p>
				<p class="portf-text">While there are other geocoding APIs out there, some free and some not, I decided to turn to an organization that specializes in data gathering for
				residences: the <a href="https://geocoding.geo.census.gov/"> U.S. Census Bureau</a>.</p>
				<p class="portf-text">First, I formatted the CSV for geocoding via the <a href="https://pandas.pydata.org/">pandas library</a>:</p>
				<ul><pre class="prettyprint portf-text">
 # format CSV for census geocoder
 df = pd.read_csv('geocodeOutput.csv', sep=',')
 df.drop(['ID','Organization','First Name','Last Name','Phone','Email'],
         axis=1, inplace=True)
 df.to_csv('geocodeOutput.csv', header=False)
				</pre></ul>
				
				<p class="portf-text">The maximum amount the U.S. Census Bureau can geocode per file is 10,000. Since I am working with a CSV that slightly exceeds that, I need to split the CSV in two. 
				While there is probably a more elegant and flexible way to program this, the following should suffice:</p>
				
				<ul><pre class="prettyprint portf-text">
 #split CSV so there aren't more than 10,000 addresses per sheet
 df1 = df.iloc[:5000]
 df2 = df.iloc[5000:]
 df1.to_csv('censusInput1.csv', index=False, header=False)
 df2.to_csv('censusInput2.csv', index=False, header=False)
				</pre></ul>
				
				<p class="portf-text">Now that I have files the census geocoder can handle, I can plug it into a function. This function will take the CSV as an input, and it will output a formatted CSV with 
				additional information, such as latitude, longitude, match accuracy, and more.</p>
				<ul><pre class="prettyprint portf-text">
 # geocode each spreadsheet 
 def censusGeocode(file, output):
     url = 'https://geocoding.geo.census.gov/geocoder/geographies/addressbatch?form'
     payload = {'benchmark':'Public_AR_Current',
		'vintage':'Current_Current',}
     files = {'addressFile': open(file)}
     r = requests.post(url, files=files, data=payload)
     results = str(r.text)
     results = re.sub('"','',results)
     results = results.split('\n')
     with open(output, 'w', newline = '') as geocodeOutput:
         w = csv.writer(geocodeOutput, delimiter=',')
         w.writerows([c.strip() for c in r.split(',')] for r in results)
 censusGeocode('censusInput1.csv', 'censusOutput1.csv')
 censusGeocode('censusInput2.csv', 'censusOutput2.csv')
				</pre></ul>
				<p class="portf-text">Each function call, which geocodes around 5,000 addresses, takes around an hour and a half.</p>  
				<h2>Formatting & Results</h2>
				<p class="portf-text">There was only one glaring error produced by the API that had to be fixed by hand. If an address had an apartment or suite number, it would put
				that suite number in an extra cell, thereby ruining the uniformity of the CSV. This was easily fixable by hand.</p>
				<img src='img/geocode_table1.png'/>
				<p><em>The bottom row is the desired format, the other five are skewed</em></p>
				<p class="portf-text">Since I have to check and fix the results by hand, I put the rest of the code into a second script.
				To reformat all of this data, I concatenate the two CSVs back together:</p>
				
				<ul><pre class="prettyprint portf-text">
 # concatenate the two CSVs
 df1 = pd.read_csv('censusOutput1.csv', sep=',', header=None)
 df2 = pd.read_csv('censusOutput2.csv', sep=',', header=None)
 frames = [df1,df2]
 result = pd.concat(frames)
 result.to_csv('censusConcat.csv', index=False)
				</pre></ul>

				<p class="portf-text" style="margin: 0 0 0 0">Out of the 11,016 rows of data…</p>
					<p class="portf-text" style="text-indent: 6%; margin: 0">
						• 9,374 were Matches (85.1%)</p>
					<p class="portf-text" style="text-indent: 6%; margin: 0">
						• 935 were Ties (8.5%)</p>
					<p class="portf-text" style="text-indent: 6%; top-margin: 0">
						• 703 were No Matches (6.4%)</p>
						
				<p class="portf-text">Out of those matches, 80.4% were exact, and 19.6% were non-exact. Match accuracies hovering around 85% <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324215/">
				seem to be adequate</a>, though there is always room for improvement. It should be noted that some of the <strong>Ties</strong> and <strong>No Matches</strong> are due to some donors
				not providing data as to where they live.
				 Moreover, this can explain how there are a total of 11,012 results (amongst match, tie, and no-match) from 11,016 rows of data.</p>
				<p class="portf-text">The geocoding output produces 14 additional columns to my CSV, four of which I need: <strong>longitude, latitude, match type,</strong> and <strong>match accuracy</strong>.
				First I dropped superfluous columns, kept the unique ID, and then concatenated the two outputs. The <a href="https://geocoding.geo.census.gov/geocoder/Geocoding_Services_API.pdf">
				API's documentation</a> isn't fantastic, so the meaning of the match type,
				<strong>Tie</strong>, is not entirely clear. However, it is clear enough that both <strong>Tie</strong> and <strong>No_Match</strong> do not produce coordinates.</p>
				
				<img src='img/geocode_table2.png'/>
				<br><br>
				<p class="portf-text">Next I stripped the CSV of any unnecessary data before merging it with the original document. Since the original document is only lacking coordinates and match types,
				I can drop everything but those four fields (latitude, longitude, match type, and match accuracy). In the next step, I'll need to merge this output with the original spreadsheet, therefore,
				values must be ordered based on its index so the spreadsheets will match up.</p>
				
				<ul><pre class="prettyprint portf-text">
 # keep unique ID, addresses, match type/accuracy, and lat/long
 df = pd.read_csv('censusConcat.csv', sep=',', engine='python')
 cols = ['1','2','3','4','7','8','9','10','13','14','15','16','17','18']
 df.drop(cols, axis=1, inplace=True)
 df.sort_values(by=['0'], inplace=True)
 df.to_csv('censusConcatStrip.csv', index=False)
				</pre></ul>
				
				<p class="portf-text">Now it is ready to merge with the original spreadsheet:</p>
				<ul><pre class="prettyprint portf-text">
 # join the census output with the original CSV
 dfA = pd.read_csv('geocodeFinal.csv', sep=',')
 dfB = pd.read_csv('censusConcatStrip.csv', sep=',')
 dfMerge = dfA.merge(dfB, right_index=True, left_index=True)
 dfMerge.to_csv('geocodeFinalRough.csv', index=False)
				</pre></ul>
				<p class="portf-text">With all data acquired, the spreadsheet just needs to be cleaned up and reformatted.</p>
				<ul><pre class="prettyprint portf-text">
 # clean up the file and rename columns
 df = pd.read_csv('geocodeFinalRough.csv', sep=',')
 df.drop(['ID','0'], axis=1, inplace=True)
 df.rename(index=str,columns={'Unnamed: 0':'serial_id',
                              '5':'match_type',
                              '6':'match_accuracy',
                              '11':'lng',
                              '12':'lat'}, inplace=True)
 df.to_csv('donors.csv', index=False)
				</pre></ul>
				<p class="portf-text">And with this, the final product can be uploaded to CARTO. The latitude and longitude do not need to be converted to a shapefile;
				CARTO simply recognizes those columns and converts it to something mappable. </p>
				<img src='img/geocode_usa.png' style="width:100%"/>
				<p><em>Donors throughout the continental United States</em></p>
				<img src='img/geocode_mich.png' style="width:100%"/>
				<p><em>Exact (grey) and non-exact (blue) matches in the Michigan area.</em></p>
				<p class="portf-text">Another version of this map is used for the <a href="https://freestok.github.io">
				header</a> of this website.</p>
		  </div>
        </div>
      </div>
    </section>
    <!-- Footer -->
    <footer>
      <div class="container text-center">
        <p>Copyright &copy; Kray Freestone 2018
		<br> Website built using HTML, CSS, Bootstrap, and Google's Code Prettify</p>
      </div>
    </footer>
	
	<!-- code-prettify by Google -->
	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?skin=desert"></script>
    
	<!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/grayscale.js"></script>

  </body>

</html>
